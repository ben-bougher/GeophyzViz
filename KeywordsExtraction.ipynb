{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = 'data/geophysics_hack_CLEAN.json'\n",
    "with open(infile, 'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 lines read, and  308 keywords loaded.\n",
      "238 lines read, and  324 keywords loaded.\n",
      "['traveltime', 'magnetization', 'interpretation', 'two-dimensional', 'datuming', 'minimum entropy', 'radiation', 'random', 'induced seismicity', 'multicomponent', 'integration', 'north america', 'diving wave', 'magnetic susceptibility', 'stoneley wave', 'oceanography', 'statistical', 'tectonics', 'scattering', 'dip moveout', 'distributed systems', 'geomatics', 'high-velocity layer', 'visualization', 'gulf of mexico', 'navigation', 'microseismic', 'density', 'vti', 'srme', 'frequency-domain', 'passive', 'production', 'maximum entropy', 'mwd', 'elimination microseismic', 'heat flow', 'resistivity log', 'sonic', 'least squares', 'australia', 'signal processing', 'risk', 'geology', 'unconsolidated', 'fluid', 'beam', 'finite element', 'sequestration', 'thermal conductivity', 'logging', 'time-domain', 'gravimeter', 'adaptive', 'avo/ava', 'inversion', 'vibroseis', 'finite difference', 'central america', '3-c', 'bed thickness', 'tti', 'standards', '2d', 'transmission', 'nuclear magnetic resonance', 'shear wave', 'depth migration', 'groundwater', 'sparse', 'poststack', 'acoustic', 'sources', 'anisotropy', 'compressional wave', 'wave propagation', 'vsp', 'fractures', 'statics', 'low frequency', 'reverse time migration', 'wide azimuth', 'steep dip', 'deconvolution', 'displacement', 'turning ray', 'spectral analysis', 'aquifer', 'k-l transform', 'sequence stratigraphy', 'profiling', 'crosscorrelation', 'migration', 'life-of-field seismic (lofs)', 'paleomagnetism', 'wave equation', 'radon', 'maximum likelihood', 'surface-related multiple elimination', 'conductivity', 'canada', 'minimum likelihood', 'nonlinear', 'tensor', 'media incompressibility', 'broadband', 'electromagnetic', 'apparent resistivity', 'horizontal wells', 'chaos', 'asia', 'shale gas', 'seismic impedance', 'south america', 'optimization', 'decomposition', 'multiples', 'reconstruction', 'ray tracing', 'nuclear', 'particle-velocity sensors', 'permanent reservoir monitoring', 'pressure sensors', 'surface consistent', 'seismic attributes', '3d', 'europe', 'travel time', 'noise', 'amplitude', 'lithology', 'processing', 'divergence', 'subsalt', 'mapping', 'subbasalt', 'time migration', 'common midpoint', 'imaging', 'separation', 'converted wave', 'salt dome', 'modeling', 'sensors', 'p-wave', 'earthquake', 'frequency-domainacoustic', 'refraction', 'water', 'ocean-bottom node', 'hydrology', 'vector processing', 'dip', 'economics', 'programming', 'obc', 'multiparameter', 'sediment', 'log analysis', 'layered', 'viscoelastic', 'isotropic', 'prestack', 'attributes', 'estimation', 'high-resolution', 'permafrost', 'numerical', 'radiometrics', 'filtering', 'neural networks', 'hydrophones', 'shear modulus', 'tomography', 'continuation', 'unconventional', 'offset', 'africa', 'stratigraphy', 'sampling', 'noiseland', 'common shot', 'air gun', 'overthrust', 'nmo', 'illumination', 'conical wave', 'velocity analysis', 'borehole geophysics', 'wavelet', 'statistics', 'fiber-optic sensors', 'elastic', 'common conversion point', 'marine', 'carbonate', 'transform', 'reflectivity', 'properties', 'dispersion', 'stacking', 'common angle', '4-c', 'waz', 'downward continuation', 'boundary conditions', 'crosswell', 'artificial intelligence', 'gps', 'fracture stimulation', 'mining', 'bulk modulus', 'reverse-time', 'reciprocity', 'shallow', 'gas', 'surface wave', 'environmental', 'geothermal', 'land', 'coherency', 'impedance', 'deepwater', 'time-lapse', 'tube wave', 'acceleration sensors', 'head waves', 'one-way', 'arrays', 'pore pressure', 'moveout', 'near surface', 'engineering', 'dmo', 'case history', 'gathers', 'gpr', 'downhole receivers', 'north sea', 'heterogeneous', 'interferometry', 'acquisition', 'resistivity', 'electrical/resistivity', 'common offset', 'mexico', 'prm', 'radial', 'rock physics', 'saturation', 'parse', 'autofocusing', 'antarctica', 'avo', 'ultrasonic', 'subtraction', 'survey design', 'seafloor', 'reservoir characterization', 'radon transform', 'permeability', 'ava', 'seismic stratigraphy', 'internal multiples', 'monitoring', 'depth conversion', 'seismic', 'resolutions', 'csem', 'fractals', 'hydrates', 'gravity', 'polarization', 'faults', 'porosity', 'electrical', 'crustal structure', 'algorithm', 'aliasing', 'interpolation', 'magnetometer', 'spectral', 'attenuation', 'common receiver', 'multiazimuth', 'induced polarization', 'magnetotelluric', 'azimuth', 'kirchhoff', 'wells', 'geophones', 'surface nuclear magnetic resonance', 'volcanics', 'measurement while drilling', 'incompressibility', 'middle east', 'water table', 'development and production', 'phase', 'invasion', 'vertical seismic profile', 'adaptive subtraction', 'parallel', 'full-waveform inversion', 's-wave', 'workstation', 'fourier', 'reflection', 'effective', 'remote sensing', 'magnetics', 'linear', 'diffraction', 'salt', 'coal', 'extrapolation', 'downhole sources', 'radial transform', 'correlation', 'velocity', '4d', 'resolution', 'archaeology', 'airborne survey']\n"
     ]
    }
   ],
   "source": [
    "KeyWords = set()\n",
    "def LoadKeywordsFromFile(infile):\n",
    "    f=open(infile,'r')\n",
    "    cnt = 0\n",
    "    for line in f:\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        curKeyword = line\n",
    "        if line[-1]=='\\n':\n",
    "            curKeyword = line[:-1]\n",
    "        KeyWords.add(curKeyword.strip().lower())\n",
    "        cnt+=1\n",
    "    print cnt,'lines read, and ', len(KeyWords),'keywords loaded.'\n",
    "    \n",
    "LoadKeywordsFromFile('data/SEG_Keywords.txt')\n",
    "LoadKeywordsFromFile('data/seg2015.json_keywords.txt')\n",
    "\n",
    "KeyWords=list(KeyWords)\n",
    "print KeyWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def GenerateKeywords(curAbstract, curTitle, curKeywords):\n",
    "    N_Keywords = len(KeyWords)        \n",
    "    kwv = np.zeros(N_Keywords)\n",
    "    extractedKW=set()\n",
    "    p=-1\n",
    "    for kw in KeyWords:\n",
    "        p+=1\n",
    "        if kw in curKeywords: #if the existing keyword is a recognized one\n",
    "            extractedKW.add(kw)\n",
    "            kwv[p]=1.0\n",
    "            continue\n",
    "        if kw in curAbstract.lower() and kw in curTitle.lower():\n",
    "            extractedKW.add(kw)\n",
    "            kwv[p]=0.9\n",
    "            continue\n",
    "        if kw in curAbstract.lower():\n",
    "            extractedKW.add(kw)\n",
    "            kwv[p]=0.5\n",
    "            continue\n",
    "        if kw in curTitle.lower():\n",
    "            extractedKW.add(kw)\n",
    "            kwv[p]=0.8\n",
    "            continue\n",
    "    return extractedKW, kwv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ln=0\n",
    "KWV=list()\n",
    "for article in data:\n",
    "    curTitle = article['title']\n",
    "    curAbstract = article['abstract']\n",
    "    curKeywords = article['keywords']\n",
    "    \n",
    "    # removing the empty articles (without title nor abstract)\n",
    "    if curAbstract==[] or curTitle==[]:\n",
    "        continue\n",
    "        \n",
    "    kwl, kwv = GenerateKeywords(curAbstract[0], curTitle[0], curKeywords)\n",
    "    KWV.append(kwv)\n",
    "    #print kwl\n",
    "    ln+=1\n",
    "    #if ln>5:\n",
    "    #    break\n",
    "    \n",
    "    # TODO: if there is any keywords, generate additional keywords if possible\n",
    "    \n",
    "    #print curTitle\n",
    "    #print curAbstract\n",
    "    #print curKeywords\n",
    "D=np.array(KWV)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2566L, 324L)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(D, aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# histogram\n",
    "Freq=sum(D)\n",
    "\n",
    "plt.plot(Freq)\n",
    "for idx, kw in enumerate(KeyWords):\n",
    "    if Freq[idx]>100:\n",
    "        plt.text(idx,Freq[idx],kw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X=pca.fit_transform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2566L, 3L)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x156d8b70>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(X[:,1],X[:,2],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:traits.has_traits:DEPRECATED: traits.has_traits.wrapped_class, 'the 'implements' class advisor has been deprecated. Use the 'provides' class decorator.\n"
     ]
    }
   ],
   "source": [
    "import mayavi.mlab as mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlab.points3d(X[:,0], X[:,1], X[:,2], colormap=\"copper\", scale_factor=.02)\n",
    "mlab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AuthorQuery = {\"Mauricio Sacchi\": 1.0, \"Xander Staal\":0.6, \"Eric Verschuur\":0.5}\n",
    "KeywordsQuery = {\"P-wave\":1.0, \"interpolation\":0.8, \"aliasing\":0.4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aliasing': 0.4, 'p-wave': 1.0, 'interpolation': 0.8}\n",
      "[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.4  0.8  0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n"
     ]
    }
   ],
   "source": [
    "# query preprocessing\n",
    "\n",
    "for k in KeywordsQuery:\n",
    "    KeywordsQuery[k.strip().lower()] = KeywordsQuery.pop(k)\n",
    "\n",
    "print KeywordsQuery\n",
    "    \n",
    "N_Keywords = len(KeyWords)        \n",
    "kqv = np.zeros(N_Keywords)\n",
    "KQ = [k for k in KeywordsQuery.keys()]\n",
    "p=0\n",
    "for kw in KeyWords:\n",
    "    if kw in KQ: #if the input keyword is a recognized one\n",
    "        kqv[p]=KeywordsQuery[kw]\n",
    "    p+=1\n",
    "print kqv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02731349327\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def KeywordScore(kqv, kv):\n",
    "    s = math.sqrt(np.sum(np.square(kqv-kv)))\n",
    "    return s\n",
    "\n",
    "kv = D[30,:]\n",
    "print KeywordScore(kqv, D[30,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAuthorsFromCitation(citation):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AuthorScore(AuthorQuery, authors):\n",
    "    return 0\n",
    "\n",
    "def CitationAuthorScore(AuthorQuery, citation):\n",
    "    return AuthorScore(AuthorQuery, GetAuthorsFromCitation(citation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "W0=2.0\n",
    "W1=1.0\n",
    "W2=0.5\n",
    "scores=[]\n",
    "for article in data:\n",
    "    authors = article['authors']\n",
    "    #kv = article['kv']\n",
    "    kv = D[cnt,:] #get the keyword vector\n",
    "    citation = article['citedby']\n",
    "    cnt+=1\n",
    "    score = W0 * AuthorScore(AuthorQuery, authors) + W1 * KeywordScore(kqv, kv) + W2 * CitationAuthorScore(AuthorQuery, citation)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
